{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_words:  {'your', 'wouldn', \"you'll\", 'those', 's', 'because', \"you've\", 'what', 'o', \"you're\", 'wasn', 'a', 'have', 'her', \"wouldn't\", 'when', 'own', 'of', 'than', 'there', \"isn't\", 'ain', 'isn', 'nor', 'out', 'hers', 'will', 'aren', 'and', 'not', \"weren't\", \"hadn't\", \"mightn't\", 'didn', 'should', 'yourself', 'too', 'them', 'from', 'i', 'me', 'most', 'here', 'but', 'where', \"wasn't\", 'ours', 'the', 'no', 'same', 'don', 'off', 'they', 'in', 'both', 'or', 'if', \"she's\", \"you'd\", 'my', \"doesn't\", 'it', 'ma', 'herself', 'on', \"should've\", 'with', 'through', 'had', 'just', \"won't\", 'then', 'were', 'few', \"needn't\", 'does', 'shouldn', 'an', 'hasn', 'shan', 'being', 'other', 'under', 'his', 'needn', 'some', 'having', 'now', 'its', 'until', 'between', 'further', 'll', 'our', 'for', \"aren't\", 'up', 'am', 'after', \"shan't\", 're', 'can', 've', 'she', 'each', 'only', \"mustn't\", 'is', 'into', 'that', 'him', 'he', 'hadn', 'myself', 'to', 'over', 'y', 'yours', 'yourselves', \"hasn't\", 'themselves', 'couldn', 'are', \"didn't\", 'we', 'so', \"couldn't\", 'm', 'be', 'which', 'once', 'you', 'do', \"don't\", 'ourselves', 'against', 'haven', 'mustn', 'all', 'while', 'theirs', \"that'll\", 'this', 'below', 'doesn', 'such', 'did', \"shouldn't\", 'again', 'was', 'whom', 'been', \"it's\", 'these', \"haven't\", 'mightn', 'before', 'why', 'himself', 't', 'about', 'down', 'during', 'above', 'itself', 'doing', 'as', 'how', 'd', 'has', 'more', 'very', 'at', 'their', 'any', 'won', 'weren', 'who', 'by'}\n",
      "['MacBook Pro Microphone', 'MacBook Pro Speakers', 'Microsoft Teams Audio', 'ZoomAudioDevice']\n",
      "should be the internal microphone:  MacBook Pro Microphone\n"
     ]
    }
   ],
   "source": [
    "import pyaudio as audio\n",
    "import speech_recognition as sr\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk import RegexpParser\n",
    "\n",
    "##############################\n",
    "only_unique_words = True\n",
    "###############33\n",
    "\n",
    "# create a list of stopwords to ignore...\n",
    "stopwords = set(['shan', 'same', \"wasn't\", \"she's\", 'they', 'off', \"needn't\", \"weren't\", 'as', 'some', 'and', 'from', 'other', \"shouldn't\", \"shan't\", 'to', 'does', 'was', 'has', 'so', 'himself', 'do', 'below', \"doesn't\", \"that'll\", 'its', 'these', 'are', 'more', 'aren', 'all', 'whom', 'shouldn', 'too', 'over', \"you've\", 'him', 'o', 'his', 'be', \"you'll\", 'out', 'against', 'most', 'if', 'hasn', 'own', 's', 'what', 'theirs', 'or', \"it's\", 'will', \"don't\", 'is', 'been', 'who', 'yourselves', 'her', 'did', 'the', 'up', 'there', 'ourselves', 'during', 'mightn', \"you'd\", 'further', 'very', 'those', 'for', 'but', 'an', 'in', 'nor', \"mightn't\", 've', 'both', 'until', 'isn', 'ain', \"didn't\", 'than', 'themselves', 'myself', \"couldn't\", 'now', 'herself', 'any', 'by', \"wouldn't\", 'about', 'after', 'here', 'doesn', 'a', 'which', 'd', 'y', 'were', 'couldn', \"aren't\", 'i', 'then', 'being', 'just', 'our', \"haven't\", 't', 'wouldn', 're', \"mustn't\", 'while', 'with', 'only', 'under', 'ma', 'again', 'can', 'ours', 'through', \"hadn't\", 'when', 'hers', \"isn't\", 'of', 'few', 'my', 'had', 'before', 'where', 'wasn', \"should've\", 'she', 'your', 'haven', 'weren', 'on', 'have', 'he', 'between', 'me', 'down', 'should', 'mustn', 'their', 'am', 'above', 'll', 'such', 'why', 'no', 'you', 'it', 'because', 'into', 'm', \"you're\", 'that', 'itself', 'not', 'hadn', \"won't\", 'we', 'don', 'doing', 'won', 'them', 'this', \"hasn't\", 'how', 'at', 'needn', 'once', 'having', 'yours', 'each', 'yourself', 'didn'])\n",
    "\n",
    "print(\"stop_words: \", stopwords)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# create a queue of the last 100 words identified by the program\n",
    "recent_text_q = []\n",
    "max_q_len = 100\n",
    "\n",
    "# activate macbook microphone stream\n",
    "## figure out what audio device our microphone is\n",
    "print(sr.Microphone.list_microphone_names())\n",
    "index = 0\n",
    "\n",
    "print(\"should be the internal microphone: \", sr.Microphone.list_microphone_names()[index])\n",
    "\n",
    "# create a microphone object\n",
    "internal_mic = sr.Microphone(device_index = index)\n",
    "# create a speech recognition object\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "\n",
    "return_str = \"\"\n",
    "words = []\n",
    "nouns = []\n",
    "verbs = []\n",
    "adjectives = []\n",
    "\n",
    "\n",
    "def fifoIn(lst, val, max_len):\n",
    "    # check if item needs to be removed\n",
    "    if len(lst) >= max_len:\n",
    "        lst.pop(0)\n",
    "    lst.append(val)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech Recognizer Enabled\n",
      "audio exported from source\n",
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.96691459,\n",
      "                           'transcript': \"really don't understand is that \"\n",
      "                                         'there are a lot of words involved '\n",
      "                                         \"here there's coffee there's things \"\n",
      "                                         \"there's baking there's swiss cheese \"\n",
      "                                         'as big catchers Andy saying the '\n",
      "                                         'Sandy bread I want to get that Sandy '\n",
      "                                         'bread and chips truffles Doritos '\n",
      "                                         'meat and chili powder chili chili '\n",
      "                                         'chili chili chili powder'},\n",
      "                       {   'transcript': \"really don't understand is that \"\n",
      "                                         'there are a lot of words involved '\n",
      "                                         \"here there's coffee there's things \"\n",
      "                                         \"there's baking there's swiss cheese \"\n",
      "                                         'as big catchers Andy saying the '\n",
      "                                         'Sandy bread I want to get that Sandy '\n",
      "                                         'bread and chips Ruffles Doritos meat '\n",
      "                                         'and chili powder chili chili chili '\n",
      "                                         'chili chili powder'},\n",
      "                       {   'transcript': \"really don't understand is that \"\n",
      "                                         'there are a lot of words involved '\n",
      "                                         \"here there's coffee there's things \"\n",
      "                                         \"there's baking there's swiss cheese \"\n",
      "                                         'as big catchers Andy saying the '\n",
      "                                         'Sandy bread I want to get that Sandy '\n",
      "                                         'bread and chips truffles Doritos '\n",
      "                                         'meat and chili pepper chili chili '\n",
      "                                         'chili chili chili powder'},\n",
      "                       {   'transcript': \"really don't understand is that \"\n",
      "                                         'there are a lot of words involved '\n",
      "                                         \"here there's coffee there's things \"\n",
      "                                         \"there's baking there's swiss cheese \"\n",
      "                                         'as big catchers Andy saying the '\n",
      "                                         'Sandy bread I want to get that Sandy '\n",
      "                                         'bread and chips truffles Doritos '\n",
      "                                         'meat and chili powdered chili chili '\n",
      "                                         'chili chili chili powder'},\n",
      "                       {   'transcript': \"really don't understand is that \"\n",
      "                                         'there are a lot of words involved '\n",
      "                                         \"here there's coffee there's things \"\n",
      "                                         \"there's baking there's swiss cheese \"\n",
      "                                         'as big catchers Andy saying the '\n",
      "                                         'Sandy bread I want to get that Sandy '\n",
      "                                         'bread and chips truffles Doritos '\n",
      "                                         'meat and chili powder chili chili '\n",
      "                                         'chili chili chili pepper'}],\n",
      "    'final': True}\n",
      "<class 'str'> of tokenized words returned from google: really don't understand is that there are a lot of words involved here there's coffee there's things there's baking there's swiss cheese as big catchers Andy saying the Sandy bread I want to get that Sandy bread and chips truffles Doritos meat and chili powder chili chili chili chili chili powder\n",
      "14 words removed from stopwords\n",
      "1 words removed from priorwords\n",
      "words taggedi: [('really', 'RB'), (\"don't\", 'JJ'), ('understand', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('there', 'EX'), ('are', 'VBP'), ('a', 'DT'), ('lot', 'NN'), ('of', 'IN'), ('words', 'NNS'), ('involved', 'VBN'), ('here', 'RB'), (\"there's\", 'JJ'), ('coffee', 'NN'), (\"there's\", 'NN'), ('things', 'NNS'), (\"there's\", 'VBP'), ('baking', 'VBG'), (\"there's\", 'NN'), ('swiss', 'JJ'), ('cheese', 'NN'), ('as', 'IN'), ('big', 'JJ'), ('catchers', 'NNS'), ('Andy', 'NNP'), ('saying', 'VBG'), ('the', 'DT'), ('Sandy', 'NNP'), ('bread', 'NN'), ('I', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('get', 'VB'), ('that', 'IN'), ('Sandy', 'NNP'), ('bread', 'NN'), ('and', 'CC'), ('chips', 'NNS'), ('truffles', 'NNS'), ('Doritos', 'NNP'), ('meat', 'NN'), ('and', 'CC'), ('chili', 'NN'), ('powder', 'NN'), ('chili', 'NN'), ('chili', 'NN'), ('chili', 'NN'), ('chili', 'NN'), ('chili', 'NN'), ('powder', 'NN')]\n",
      "52 identified words:  ['the', 'the', 'really', \"don't\", 'understand', 'is', 'that', 'there', 'are', 'a', 'lot', 'of', 'words', 'involved', 'here', \"there's\", 'coffee', \"there's\", 'things', \"there's\", 'baking', \"there's\", 'swiss', 'cheese', 'as', 'big', 'catchers', 'Andy', 'saying', 'Sandy', 'bread', 'I', 'want', 'to', 'get', 'that', 'Sandy', 'bread', 'and', 'chips', 'truffles', 'Doritos', 'meat', 'and', 'chili', 'powder', 'chili', 'chili', 'chili', 'chili', 'chili', 'powder']\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    # capture audio from the microphone\n",
    "    with internal_mic as source:\n",
    "        # adjust for background noise to increase success rate\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        # identify any spoken words in the audio\n",
    "        print(\"Speech Recognizer Enabled\");\n",
    "        audio = recognizer.listen(source)\n",
    "        print(\"audio exported from source\")\n",
    "        raw_string = \"the the \"\n",
    "        try:\n",
    "            raw_string = recognizer.recognize_google(audio)\n",
    "        except:\n",
    "            print(\" .\")\n",
    "\n",
    "        print(\"{} of tokenized words returned from google: {}\".format(type(raw_string), raw_string))\n",
    "        # remove words from string\n",
    "\n",
    "        return_str = raw_string.split()\n",
    "        wn = len(return_str)\n",
    "        # remove any words in the stopwords\n",
    "        words = [i for i in return_str if i not in stopwords]\n",
    "        print(\"{} words removed from stopwords\".format(wn - len(words)))\n",
    "        words = [i for i in return_str if i not in recent_text_q]\n",
    "        print(\"{} words removed from priorwords\".format(wn - len(words)))\n",
    "        # append the word type to the word string, returnig a tuple (str, type)\n",
    "        words_tags = pos_tag(return_str)\n",
    "        print(\"words taggedi: {}\".format(words_tags))\n",
    "        # create a chunk grammar statement\n",
    "        \"\"\"\n",
    "            According to the rule you created, your chunks:\n",
    "            Start with an optional (?) determiner ('DT')\n",
    "            Can have any number (*) of adjectives (JJ)\n",
    "            End with a noun (<NN>)\n",
    "        grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "        chunk_parser = RegexpParser(grammar)\n",
    "        tree = chunk_parser.parse(words_tags)\n",
    "        \"\"\"\n",
    "        # append spoken words to the running FIFO of all words\n",
    "        for word in words:\n",
    "            recent_text_q = fifoIn(recent_text_q, word, max_q_len)\n",
    "            # if append to buffer according to type of grammer\n",
    "\n",
    "\n",
    "        print(\"{} identified words: \".format(len(recent_text_q)),\n",
    "              recent_text_q)\n",
    "\n",
    "# classify words and add them to FIFO buffers\n",
    "\n",
    "# print current FIFO buffers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'the', 'really', \"don't\", 'understand', 'is', 'that', 'there', 'are', 'a', 'lot', 'of', 'words', 'involved', 'here', \"there's\", 'coffee', \"there's\", 'things', \"there's\", 'baking', \"there's\", 'swiss', 'cheese', 'as', 'big', 'catchers', 'Andy', 'saying', 'Sandy', 'bread', 'I', 'want', 'to', 'get', 'that', 'Sandy', 'bread', 'and', 'chips', 'truffles', 'Doritos', 'meat', 'and', 'chili', 'powder', 'chili', 'chili', 'chili', 'chili', 'chili', 'powder']\n",
      "51 word tags tuples : [('really', 'RB'), (\"don't\", 'JJ'), ('understand', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('there', 'EX'), ('are', 'VBP'), ('a', 'DT'), ('lot', 'NN'), ('of', 'IN'), ('words', 'NNS'), ('involved', 'VBN'), ('here', 'RB'), (\"there's\", 'JJ'), ('coffee', 'NN'), (\"there's\", 'NN'), ('things', 'NNS'), (\"there's\", 'VBP'), ('baking', 'VBG'), (\"there's\", 'NN'), ('swiss', 'JJ'), ('cheese', 'NN'), ('as', 'IN'), ('big', 'JJ'), ('catchers', 'NNS'), ('Andy', 'NNP'), ('saying', 'VBG'), ('the', 'DT'), ('Sandy', 'NNP'), ('bread', 'NN'), ('I', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('get', 'VB'), ('that', 'IN'), ('Sandy', 'NNP'), ('bread', 'NN'), ('and', 'CC'), ('chips', 'NNS'), ('truffles', 'NNS'), ('Doritos', 'NNP'), ('meat', 'NN'), ('and', 'CC'), ('chili', 'NN'), ('powder', 'NN'), ('chili', 'NN'), ('chili', 'NN'), ('chili', 'NN'), ('chili', 'NN'), ('chili', 'NN'), ('powder', 'NN')]\n",
      "word : ('really', 'RB')\n",
      "word : (\"don't\", 'JJ')\n",
      "word : ('understand', 'NN')\n",
      "word : ('is', 'VBZ')\n",
      "word : ('that', 'IN')\n",
      "word : ('there', 'EX')\n",
      "word : ('are', 'VBP')\n",
      "word : ('a', 'DT')\n",
      "word : ('lot', 'NN')\n",
      "word : ('of', 'IN')\n",
      "word : ('words', 'NNS')\n",
      "word : ('involved', 'VBN')\n",
      "word : ('here', 'RB')\n",
      "word : (\"there's\", 'JJ')\n",
      "word : ('coffee', 'NN')\n",
      "word : (\"there's\", 'NN')\n",
      "word : ('things', 'NNS')\n",
      "word : (\"there's\", 'VBP')\n",
      "word : ('baking', 'VBG')\n",
      "word : (\"there's\", 'NN')\n",
      "word : ('swiss', 'JJ')\n",
      "word : ('cheese', 'NN')\n",
      "word : ('as', 'IN')\n",
      "word : ('big', 'JJ')\n",
      "word : ('catchers', 'NNS')\n",
      "word : ('Andy', 'NNP')\n",
      "word : ('saying', 'VBG')\n",
      "word : ('the', 'DT')\n",
      "word : ('Sandy', 'NNP')\n",
      "word : ('bread', 'NN')\n",
      "word : ('I', 'PRP')\n",
      "word : ('want', 'VBP')\n",
      "word : ('to', 'TO')\n",
      "word : ('get', 'VB')\n",
      "word : ('that', 'IN')\n",
      "word : ('Sandy', 'NNP')\n",
      "word : ('bread', 'NN')\n",
      "word : ('and', 'CC')\n",
      "word : ('chips', 'NNS')\n",
      "word : ('truffles', 'NNS')\n",
      "word : ('Doritos', 'NNP')\n",
      "word : ('meat', 'NN')\n",
      "word : ('and', 'CC')\n",
      "word : ('chili', 'NN')\n",
      "word : ('powder', 'NN')\n",
      "word : ('chili', 'NN')\n",
      "word : ('chili', 'NN')\n",
      "word : ('chili', 'NN')\n",
      "word : ('chili', 'NN')\n",
      "word : ('chili', 'NN')\n",
      "word : ('powder', 'NN')\n",
      "52 nouns are saved: ['understand', 'lot', 'words', 'coffee', \"there's\", 'things', \"there's\", 'cheese', 'catchers', 'Andy', 'Sandy', 'bread', 'Sandy', 'bread', 'chips', 'truffles', 'Doritos', 'meat', 'chili', 'powder', 'chili', 'chili', 'chili', 'chili', 'chili', 'powder', 'understand', 'lot', 'words', 'coffee', \"there's\", 'things', \"there's\", 'cheese', 'catchers', 'Andy', 'Sandy', 'bread', 'Sandy', 'bread', 'chips', 'truffles', 'Doritos', 'meat', 'chili', 'powder', 'chili', 'chili', 'chili', 'chili', 'chili', 'powder']\n",
      "16 verbs are saved: ['is', 'are', 'involved', \"there's\", 'baking', 'saying', 'want', 'get', 'is', 'are', 'involved', \"there's\", 'baking', 'saying', 'want', 'get']\n",
      "8 adjectives are saved: [\"don't\", \"there's\", 'swiss', 'big', \"don't\", \"there's\", 'swiss', 'big']\n"
     ]
    }
   ],
   "source": [
    "def getStrFromTuple(lst):\n",
    "    r = \"\"\n",
    "    for l in lst:\n",
    "        r.join(l[0]).join(\" \")\n",
    "    return r\n",
    "\n",
    "def getStrFromList(lst):\n",
    "    print(lst)\n",
    "    r = \"\"\n",
    "    for i in range(len(lst)):\n",
    "        print(i)\n",
    "        r.join(lst[i]).join(\" \")\n",
    "        print(r)\n",
    "    return r\n",
    "\n",
    "print(recent_text_q)\n",
    "# reconstruct a string to be sent to a stable diffusion network\n",
    "print(\"{} word tags tuples : {}\".format(len(words_tags), words_tags))\n",
    "for word in words_tags:\n",
    "    print(\"word : {}\".format(word))\n",
    "    if word[1].startswith(\"NN\"):\n",
    "        nouns = fifoIn(nouns, word[0], max_q_len)\n",
    "    elif word[1].startswith(\"VB\"):\n",
    "        verbs = fifoIn(verbs, word[0], max_q_len)\n",
    "    elif word[1].startswith(\"JJ\"):\n",
    "        adjectives = fifoIn(adjectives, word[0], max_q_len)\n",
    "    prompt_string = \"\"\n",
    "\n",
    "print(\"{} nouns are saved: {}\".format(len(nouns), nouns))\n",
    "print(\"{} verbs are saved: {}\".format(len(verbs), verbs))\n",
    "print(\"{} adjectives are saved: {}\".format(len(adjectives), adjectives))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to Speech using espeak in OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "powder swiss cheese there's chili, lot swiss chili are meat, lot big bread want there's\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# okay, now it is time to construct our string\n",
    "\n",
    "def addSimplePhraise():\n",
    "    # generate multiple phraises, then determine best one using nltk\n",
    "    return \"{} {} {} {} {}\".format(randomNoun(), randomAdj(), randomNoun(), randomVerb(), randomNoun())\n",
    "\n",
    "def randomNoun():\n",
    "    return nouns[random.randint(0, len(nouns) - 1)]\n",
    "\n",
    "def randomVerb():\n",
    "    return verbs[random.randint(0, len(verbs) - 1)]\n",
    "\n",
    "def randomAdj():\n",
    "    return adjectives[random.randint(0, len(adjectives) - 1)]\n",
    "\n",
    "prompt_string = \"{}, {}, {}\".format(addSimplePhraise(), addSimplePhraise(), addSimplePhraise())\n",
    "print(prompt_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender = 'm' # as oppose to  'f'\n",
    "vnum = str(random.randint(1, 5))\n",
    "voice = '{}{}'.format(gender, vnum)\n",
    "pitch = str(random.randint(10, 90))\n",
    "command = 'espeak -s 180 -v {} -p {} \"{}\"\\n'.format(voice, pitch, prompt_string)\n",
    "print(\"using espeak to say the following command {}\".format(prompt_string))\n",
    "os.system(command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84f100e172d30523e09c9ea3b146d7b4e44e98c1b89071d9f6625876d1cbe325"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
